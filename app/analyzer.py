import requests
import json
from typing import List, Dict
import time
import os
import argparse
import sys

sys.stdout.reconfigure(line_buffering=True)

def parse_args():
    parser = argparse.ArgumentParser(
        description="ç½‘ç»œçƒ­æœåˆ†æå·¥å…· - å¯é…ç½®åŒ–ç‰ˆæœ¬ (Powered by Ollama)"
    )

    parser.add_argument("--hot-search-api", type=str, required=True,
                        help="çƒ­æœæ•°æ®æ¥å£åœ°å€ï¼Œä¾‹å¦‚ http://192.168.0.1:10880")

    parser.add_argument("--ollama-api", type=str, required=True,
                        help="Ollama API åœ°å€ï¼Œä¾‹å¦‚ http://192.168.0.1:11434")

    parser.add_argument("--ollama-model", type=str, default="qwen2.5:14b",
                        help="Ollama æ¨¡å‹åç§°ï¼ˆé»˜è®¤ï¼šqwen2.5:14bï¼‰")

    parser.add_argument("--save-dir", type=str, default=os.path.expanduser("~/hot_trends_analysis/outputs"),
                        help="ç»“æœä¿å­˜ç›®å½•")

    parser.add_argument("--platforms", type=str, nargs="+", default=[
        "weibo", "zhihu", "baidu", "bilibili", "douyin",
        "toutiao", "36kr", "ithome", "github", "hackernews"
    ], help="è¦åˆ†æçš„å¹³å°åˆ—è¡¨ï¼ˆç©ºæ ¼åˆ†éš”ï¼‰")

    parser.add_argument("--topics-per-platform", type=int, default=10,
                        help="æ¯ä¸ªå¹³å°æå–çš„çƒ­æœæ¡æ•°")

    parser.add_argument("--max-retries", type=int, default=5,
                        help="æœ€å¤§é‡è¯•æ¬¡æ•°")

    parser.add_argument("--retry-delay", type=float, default=5,
                        help="é‡è¯•ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰")

    return parser.parse_args()


def fetch_hot_search(platform: str, api_url: str, max_retries: int, retry_delay: float) -> Dict:
    """è·å–æŒ‡å®šå¹³å°çš„çƒ­æœæ•°æ®ï¼Œå¤±è´¥åè‡ªåŠ¨é‡è¯•"""
    for attempt in range(1, max_retries + 1):
        try:
            url = f"{api_url}/{platform}"
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            if attempt < max_retries:
                print(f"âš ï¸  è·å– {platform} æ•°æ®å¤±è´¥ (å°è¯• {attempt}/{max_retries}): {e}", flush=True)
                print(f"   ç­‰å¾… {retry_delay} ç§’åé‡è¯•...", flush=True)
                time.sleep(retry_delay)
            else:
                print(f"âŒ è·å– {platform} æ•°æ®å¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡: {e}", flush=True)
                return None
    return None


def extract_hot_topics(data: Dict, platform: str, topics_per_platform: int) -> List[str]:
    """ä»APIè¿”å›çš„æ•°æ®ä¸­æå–çƒ­æœæ ‡é¢˜"""
    topics = []
    try:
        if data and "data" in data:
            items = data["data"]
            for item in items[:topics_per_platform]:
                title = item.get("title", "")
                if title:
                    topics.append(title)
    except Exception as e:
        print(f"âš ï¸  è§£æ {platform} æ•°æ®æ—¶å‡ºé”™: {e}", flush=True)
    return topics


def call_ollama(prompt: str, ollama_api: str, model_name: str,
                max_retries: int, retry_delay: float) -> str:
    """è°ƒç”¨æœ¬åœ°Ollamaè¿›è¡Œåˆ†æï¼Œå¤±è´¥åè‡ªåŠ¨é‡è¯•"""
    for attempt in range(1, max_retries + 1):
        try:
            payload = {
                "model": model_name,
                "messages": [{"role": "user", "content": prompt}],
                "stream": False,
                "options": {
                    "temperature": 0.7,
                    "num_predict": 800,
                    "num_ctx": 2048
                }
            }

            chat_api = f"{ollama_api}/api/chat"
            if attempt == 1:
                print(f"ğŸ”— è°ƒç”¨ Ollama API: {chat_api}", flush=True)

            response = requests.post(chat_api, json=payload, timeout=180)
            response.raise_for_status()
            result = response.json()

            if "message" in result and "content" in result["message"]:
                return result["message"]["content"]
            return ""
        except Exception as e:
            if attempt < max_retries:
                print(f"âš ï¸  Ollama è°ƒç”¨å¤±è´¥ (å°è¯• {attempt}/{max_retries}): {e}", flush=True)
                print(f"   ç­‰å¾… {retry_delay} ç§’åé‡è¯•...", flush=True)
                time.sleep(retry_delay)
            else:
                print(f"âŒ Ollama è°ƒç”¨å¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡: {e}", flush=True)
                return ""
    return ""


def ensure_ollama_model(ollama_api: str, model_name: str) -> bool:
    """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™è‡ªåŠ¨æ‹‰å–"""
    try:
        response = requests.get(f"{ollama_api}/api/tags", timeout=10)
        response.raise_for_status()
        models = response.json().get("models", [])
        model_names = [m["name"] for m in models]

        if model_name in model_names:
            print(f"âœ… æ¨¡å‹å·²å­˜åœ¨: {model_name}", flush=True)
            return True

        print(f"ğŸ“¦ æ¨¡å‹ä¸å­˜åœ¨ï¼Œæ­£åœ¨æ‹‰å–: {model_name} ...", flush=True)
        pull_response = requests.post(f"{ollama_api}/api/pull", json={"name": model_name}, stream=True, timeout=600)

        for line in pull_response.iter_lines():
            if line:
                try:
                    msg = json.loads(line.decode('utf-8'))
                    status = msg.get("status")
                    if status:
                        print(f"   {status}", flush=True)
                except json.JSONDecodeError:
                    pass

        print(f"âœ… æ¨¡å‹æ‹‰å–å®Œæˆ: {model_name}", flush=True)
        return True
    except Exception as e:
        print(f"âŒ æ£€æŸ¥/æ‹‰å–æ¨¡å‹æ—¶å‡ºé”™: {e}", flush=True)
        return False


def analyze_hot_trends(args):
    """ä¸»å‡½æ•°ï¼šåˆ†æç½‘ç»œçƒ­é—¨è¶‹åŠ¿"""
    print("ğŸš€ å¼€å§‹æ”¶é›†çƒ­æœæ•°æ®...\n", flush=True)

    if not ensure_ollama_model(args.ollama_api, args.ollama_model):
        print("âŒ æ— æ³•å‡†å¤‡ Ollama æ¨¡å‹ï¼Œç»ˆæ­¢åˆ†æã€‚", flush=True)
        return

    all_topics = {}

    for platform in args.platforms:
        print(f"ğŸ“¡ æ­£åœ¨è·å– {platform} çƒ­æœ...", flush=True)
        data = fetch_hot_search(platform, args.hot_search_api, args.max_retries, args.retry_delay)

        if data:
            topics = extract_hot_topics(data, platform, args.topics_per_platform)
            if topics:
                all_topics[platform] = topics
                print(f"âœ… {platform}: è·å–åˆ° {len(topics)} æ¡çƒ­æœ", flush=True)
            else:
                print(f"âš ï¸  {platform}: æœªèƒ½æå–åˆ°çƒ­æœå†…å®¹", flush=True)

        time.sleep(0.5)

    if not all_topics:
        print("\nâŒ æœªèƒ½è·å–åˆ°ä»»ä½•çƒ­æœæ•°æ®ï¼Œè¯·æ£€æŸ¥APIæœåŠ¡æ˜¯å¦æ­£å¸¸", flush=True)
        return

    print("\n" + "="*60, flush=True)
    print("ğŸ¤– æ­£åœ¨ä½¿ç”¨ Ollama åˆ†æçƒ­æœè¶‹åŠ¿...", flush=True)
    print("="*60 + "\n", flush=True)

    topics_text = ""
    for platform, topics in all_topics.items():
        topics_text += f"\nã€{platform}ã€‘\n"
        for i, topic in enumerate(topics, 1):
            topics_text += f"{i}. {topic}\n"

    prompt = f"""è¯·é˜…è¯»ä»¥ä¸‹æ¥è‡ªå¤šä¸ªå¹³å°çš„çƒ­æœæ•°æ®ï¼Œå†™ä¸€ç¯‡æµç•…çš„æ€»ç»“æŠ¥å‘Šï¼Œæè¿°å½“å‰ç½‘ç»œçƒ­é—¨è¶‹åŠ¿ã€‚

è¦æ±‚ï¼š
- ç”¨è‡ªç„¶æµç•…çš„æ®µè½å½¢å¼å†™ä½œï¼Œä¸è¦ä½¿ç”¨åˆ†ç‚¹åˆ—è¡¨æˆ–æ ‡é¢˜
- è¦å°†è¶‹åŠ¿åˆ†æå’Œå…·ä½“äº‹å®æœ‰æœºç»“åˆï¼Œå°¤å…¶è¦æ˜ç¡®æŒ‡å‡ºä¿¡æºå“ªä¸ªå¹³å°ã€åŸå§‹å†…å®¹æ˜¯ä»€ä¹ˆ
- è¢«å¤šä¸ªå¹³å°æåˆ°çš„å†…å®¹é‡ç‚¹åˆ†æ
- åœ¨æ–‡æœ«åˆ—ä¸¾å‡ºè¢«å…¨ç½‘æ‰€å…³æ³¨çš„åŸå§‹å†…å®¹
- å…¨æ–‡æ§åˆ¶åœ¨300-500å­—ï¼Œè¯­è¨€ä¸“ä¸šä½†æ˜“è¯»
- éœ€è¦æ³¨æ„å¹³å°è°ƒç”¨åç§°å’Œç«™ç‚¹åçš„å¯¹åº”å…³ç³»ï¼Œåœ¨æ–‡ä¸­è¦ä½¿ç”¨ç«™ç‚¹åï¼š
| **ç«™ç‚¹**         | **ç±»åˆ«**     | **è°ƒç”¨åç§°**   |
| ---------------- | ------------ | -------------- | 
| å“”å“©å“”å“©         | çƒ­é—¨æ¦œ       | bilibili       | 
| AcFun            | æ’è¡Œæ¦œ       | acfun          | 
| å¾®åš             | çƒ­æœæ¦œ       | weibo          | 
| çŸ¥ä¹             | çƒ­æ¦œ         | zhihu          | 
| çŸ¥ä¹æ—¥æŠ¥         | æ¨èæ¦œ       | zhihu-daily    | 
| ç™¾åº¦             | çƒ­æœæ¦œ       | baidu          | 
| æŠ–éŸ³             | çƒ­ç‚¹æ¦œ       | douyin         | 
| å¿«æ‰‹             | çƒ­ç‚¹æ¦œ       | kuaishou       | 
| è±†ç“£ç”µå½±         | æ–°ç‰‡æ¦œ       | douban-movie   | 
| è±†ç“£è®¨è®ºå°ç»„     | è®¨è®ºç²¾é€‰     | douban-group   | 
| ç™¾åº¦è´´å§         | çƒ­è®®æ¦œ       | tieba          | 
| å°‘æ•°æ´¾           | çƒ­æ¦œ         | sspai          | 
| ITä¹‹å®¶           | çƒ­æ¦œ         | ithome         | 
| ITä¹‹å®¶ã€Œå–œåŠ ä¸€ã€ | æœ€æ–°åŠ¨æ€     | ithome-xijiayi | 
| ç®€ä¹¦             | çƒ­é—¨æ¨è     | jianshu        | 
| æœå£³             | çƒ­é—¨æ–‡ç«      | guokr          | 
| æ¾æ¹ƒæ–°é—»         | çƒ­æ¦œ         | thepaper       | 
| ä»Šæ—¥å¤´æ¡         | çƒ­æ¦œ         | toutiao        | 
| 36 æ°ª            | çƒ­æ¦œ         | 36kr           | 
| 51CTO            | æ¨èæ¦œ       | 51cto          | 
| CSDN             | æ’è¡Œæ¦œ       | csdn           | 
| NodeSeek         | æœ€æ–°åŠ¨æ€     | nodeseek       | 
| ç¨€åœŸæ˜é‡‘         | çƒ­æ¦œ         | juejin         | 
| è…¾è®¯æ–°é—»         | çƒ­ç‚¹æ¦œ       | qq-news        | 
| æ–°æµªç½‘           | çƒ­æ¦œ         | sina           | 
| æ–°æµªæ–°é—»         | çƒ­ç‚¹æ¦œ       | sina-news      | 
| ç½‘æ˜“æ–°é—»         | çƒ­ç‚¹æ¦œ       | netease-news   | 
| å¾çˆ±ç ´è§£         | æ¦œå•         | 52pojie        | 
| å…¨çƒä¸»æœºäº¤æµ     | æ¦œå•         | hostloc        | 
| è™å—…             | 24å°æ—¶       | huxiu          | 
| é…·å®‰             | çƒ­æ¦œ         | coolapk        | 
| è™æ‰‘             | æ­¥è¡Œè¡—çƒ­å¸–   | hupu           | 
| çˆ±èŒƒå„¿           | å¿«è®¯         | ifanr          | 
| è‹±é›„è”ç›Ÿ         | æ›´æ–°å…¬å‘Š     | lol            | 
| ç±³æ¸¸ç¤¾           | æœ€æ–°æ¶ˆæ¯     | miyoushe       | 
| åŸç¥             | æœ€æ–°æ¶ˆæ¯     | genshin        | 
| å´©å3            | æœ€æ–°åŠ¨æ€     | honkai         | 
| å´©åï¼šæ˜Ÿç©¹é“é“   | æœ€æ–°åŠ¨æ€     | starrail       | 
| å¾®ä¿¡è¯»ä¹¦         | é£™å‡æ¦œ       | weread         | 
| NGA              | çƒ­å¸–         | ngabbs         | 
| V2EX             | ä¸»é¢˜æ¦œ       | v2ex           | 
| HelloGitHub      | Trending     | hellogithub    | 
| ä¸­å¤®æ°”è±¡å°       | å…¨å›½æ°”è±¡é¢„è­¦ | weatheralarm   | 
| ä¸­å›½åœ°éœ‡å°       | åœ°éœ‡é€ŸæŠ¥     | earthquake     | 
| å†å²ä¸Šçš„ä»Šå¤©     | æœˆ-æ—¥        | history        |

è¯·ç”¨ä¸­æ–‡æ’°å†™è¿™ç¯‡æ€»ç»“ã€‚

{topics_text}

"""
    
    print(f"\nğŸ“ å®Œæ•´æç¤ºè¯é¢„è§ˆ:\n{'-'*60}")
    print(prompt[:500] + "..." if len(prompt) > 500 else prompt)
    print(f"{'-'*60}\n")

    analysis_result = call_ollama(prompt, args.ollama_api, args.ollama_model,
                                  args.max_retries, args.retry_delay)

    if analysis_result:
        print("\n" + "="*60, flush=True)
        print("ğŸ“Š åˆ†æç»“æœ", flush=True)
        print("="*60, flush=True)
        print(analysis_result, flush=True)
        print("\n" + "="*60, flush=True)

        os.makedirs(args.save_dir, exist_ok=True)
        output = {
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "platforms_analyzed": list(all_topics.keys()),
            "raw_data": all_topics,
            "analysis": analysis_result
        }
        filename = os.path.join(args.save_dir,
                                f"hot_trends_analysis_{time.strftime('%Y%m%d_%H%M%S')}.json")

        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(output, f, ensure_ascii=False, indent=2)

        print(f"\nğŸ’¾ åˆ†æç»“æœå·²ä¿å­˜è‡³: {filename}", flush=True)
    else:
        print("\nâŒ Ollamaåˆ†æå¤±è´¥ï¼Œè¯·æ£€æŸ¥OllamaæœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ", flush=True)


if __name__ == "__main__":
    print("="*60, flush=True)
    print("   ç½‘ç»œçƒ­æœåˆ†æå·¥å…· - å‘½ä»¤è¡Œé…ç½®ç‰ˆ", flush=True)
    print("="*60 + "\n", flush=True)

    args = parse_args()
    analyze_hot_trends(args)

    print("\nâœ¨ åˆ†æå®Œæˆï¼", flush=True)